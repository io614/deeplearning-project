{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ae3a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d38815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils\n",
    "import itertools\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='sklearn.linear_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1feae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dicts = utils.get_config_dicts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ef2be1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>folder</th>\n",
       "      <th>base_model</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>mask_model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>sampling</th>\n",
       "      <th>d_path</th>\n",
       "      <th>z_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_EleutherAI-gpt-neo-125...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_Eleuth...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_Eleuth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_bert-base-cased_t5-bas...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_bert-b...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_bert-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_gpt2-medium_t5-base_ge...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2-m...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_gpt2_t5-base_german_temp</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2_t...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_roberta-base_t5-base_g...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_robert...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_robert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2_EleutherAI-gpt-neo-125m_t5-base_german_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_EleutherAI-gpt-neo-125m_t...</td>\n",
       "      <td>results/permute/gpt2_EleutherAI-gpt-neo-125m_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt2_bert-base-cased_t5-base_german_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_bert-base-cased_t5-base_g...</td>\n",
       "      <td>results/permute/gpt2_bert-base-cased_t5-base_g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt2_gpt2-medium_t5-base_german_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_gpt2-medium_t5-base_germa...</td>\n",
       "      <td>results/permute/gpt2_gpt2-medium_t5-base_germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt2_gpt2_t5-base_german_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_gpt2_t5-base_german_temp/...</td>\n",
       "      <td>results/permute/gpt2_gpt2_t5-base_german_temp/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt2_roberta-base_t5-base_german_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_roberta-base_t5-base_germ...</td>\n",
       "      <td>results/permute/gpt2_roberta-base_t5-base_germ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2-medium_EleutherAI-gpt-neo-125m_t5-base_ge...</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_EleutherAI-gpt-neo...</td>\n",
       "      <td>results/permute/gpt2-medium_EleutherAI-gpt-neo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt2-medium_bert-base-cased_t5-base_german_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_bert-base-cased_t5...</td>\n",
       "      <td>results/permute/gpt2-medium_bert-base-cased_t5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt2-medium_gpt2-medium_t5-base_german_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2-medium_t5-bas...</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2-medium_t5-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2-medium_gpt2_t5-base_german_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2_t5-base_germa...</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2_t5-base_germa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt2-medium_roberta-base_t5-base_german_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>german</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_roberta-base_t5-ba...</td>\n",
       "      <td>results/permute/gpt2-medium_roberta-base_t5-ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_EleutherAI-gpt-neo-125...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_Eleuth...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_Eleuth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_bert-base-cased_t5-bas...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_bert-b...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_bert-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_gpt2-medium_t5-base_xs...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2-m...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_gpt2_t5-base_xsum_temp</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2_t...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_gpt2_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EleutherAI-gpt-neo-125m_roberta-base_t5-base_x...</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_robert...</td>\n",
       "      <td>results/permute/EleutherAI-gpt-neo-125m_robert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt2_EleutherAI-gpt-neo-125m_t5-base_xsum_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_EleutherAI-gpt-neo-125m_t...</td>\n",
       "      <td>results/permute/gpt2_EleutherAI-gpt-neo-125m_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt2_bert-base-cased_t5-base_xsum_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_bert-base-cased_t5-base_x...</td>\n",
       "      <td>results/permute/gpt2_bert-base-cased_t5-base_x...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt2_gpt2-medium_t5-base_xsum_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_gpt2-medium_t5-base_xsum_...</td>\n",
       "      <td>results/permute/gpt2_gpt2-medium_t5-base_xsum_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt2_gpt2_t5-base_xsum_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_gpt2_t5-base_xsum_temp/20...</td>\n",
       "      <td>results/permute/gpt2_gpt2_t5-base_xsum_temp/20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt2_roberta-base_t5-base_xsum_temp</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2_roberta-base_t5-base_xsum...</td>\n",
       "      <td>results/permute/gpt2_roberta-base_t5-base_xsum...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2-medium_EleutherAI-gpt-neo-125m_t5-base_xs...</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_EleutherAI-gpt-neo...</td>\n",
       "      <td>results/permute/gpt2-medium_EleutherAI-gpt-neo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2-medium_bert-base-cased_t5-base_xsum_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_bert-base-cased_t5...</td>\n",
       "      <td>results/permute/gpt2-medium_bert-base-cased_t5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt2-medium_gpt2-medium_t5-base_xsum_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2-medium_t5-bas...</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2-medium_t5-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2-medium_gpt2_t5-base_xsum_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2_t5-base_xsum_...</td>\n",
       "      <td>results/permute/gpt2-medium_gpt2_t5-base_xsum_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt2-medium_roberta-base_t5-base_xsum_temp</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>t5-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>temp</td>\n",
       "      <td>results/permute/gpt2-medium_roberta-base_t5-ba...</td>\n",
       "      <td>results/permute/gpt2-medium_roberta-base_t5-ba...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               folder  \\\n",
       "0   EleutherAI-gpt-neo-125m_EleutherAI-gpt-neo-125...   \n",
       "2   EleutherAI-gpt-neo-125m_bert-base-cased_t5-bas...   \n",
       "4   EleutherAI-gpt-neo-125m_gpt2-medium_t5-base_ge...   \n",
       "6    EleutherAI-gpt-neo-125m_gpt2_t5-base_german_temp   \n",
       "8   EleutherAI-gpt-neo-125m_roberta-base_t5-base_g...   \n",
       "20   gpt2_EleutherAI-gpt-neo-125m_t5-base_german_temp   \n",
       "22           gpt2_bert-base-cased_t5-base_german_temp   \n",
       "24               gpt2_gpt2-medium_t5-base_german_temp   \n",
       "26                      gpt2_gpt2_t5-base_german_temp   \n",
       "28              gpt2_roberta-base_t5-base_german_temp   \n",
       "10  gpt2-medium_EleutherAI-gpt-neo-125m_t5-base_ge...   \n",
       "12    gpt2-medium_bert-base-cased_t5-base_german_temp   \n",
       "14        gpt2-medium_gpt2-medium_t5-base_german_temp   \n",
       "16               gpt2-medium_gpt2_t5-base_german_temp   \n",
       "18       gpt2-medium_roberta-base_t5-base_german_temp   \n",
       "1   EleutherAI-gpt-neo-125m_EleutherAI-gpt-neo-125...   \n",
       "3   EleutherAI-gpt-neo-125m_bert-base-cased_t5-bas...   \n",
       "5   EleutherAI-gpt-neo-125m_gpt2-medium_t5-base_xs...   \n",
       "7      EleutherAI-gpt-neo-125m_gpt2_t5-base_xsum_temp   \n",
       "9   EleutherAI-gpt-neo-125m_roberta-base_t5-base_x...   \n",
       "21     gpt2_EleutherAI-gpt-neo-125m_t5-base_xsum_temp   \n",
       "23             gpt2_bert-base-cased_t5-base_xsum_temp   \n",
       "25                 gpt2_gpt2-medium_t5-base_xsum_temp   \n",
       "27                        gpt2_gpt2_t5-base_xsum_temp   \n",
       "29                gpt2_roberta-base_t5-base_xsum_temp   \n",
       "11  gpt2-medium_EleutherAI-gpt-neo-125m_t5-base_xs...   \n",
       "13      gpt2-medium_bert-base-cased_t5-base_xsum_temp   \n",
       "15          gpt2-medium_gpt2-medium_t5-base_xsum_temp   \n",
       "17                 gpt2-medium_gpt2_t5-base_xsum_temp   \n",
       "19         gpt2-medium_roberta-base_t5-base_xsum_temp   \n",
       "\n",
       "                 base_model            scoring_model mask_model dataset  \\\n",
       "0   EleutherAI-gpt-neo-125m  EleutherAI-gpt-neo-125m    t5-base  german   \n",
       "2   EleutherAI-gpt-neo-125m          bert-base-cased    t5-base  german   \n",
       "4   EleutherAI-gpt-neo-125m              gpt2-medium    t5-base  german   \n",
       "6   EleutherAI-gpt-neo-125m                     gpt2    t5-base  german   \n",
       "8   EleutherAI-gpt-neo-125m             roberta-base    t5-base  german   \n",
       "20                     gpt2  EleutherAI-gpt-neo-125m    t5-base  german   \n",
       "22                     gpt2          bert-base-cased    t5-base  german   \n",
       "24                     gpt2              gpt2-medium    t5-base  german   \n",
       "26                     gpt2                     gpt2    t5-base  german   \n",
       "28                     gpt2             roberta-base    t5-base  german   \n",
       "10              gpt2-medium  EleutherAI-gpt-neo-125m    t5-base  german   \n",
       "12              gpt2-medium          bert-base-cased    t5-base  german   \n",
       "14              gpt2-medium              gpt2-medium    t5-base  german   \n",
       "16              gpt2-medium                     gpt2    t5-base  german   \n",
       "18              gpt2-medium             roberta-base    t5-base  german   \n",
       "1   EleutherAI-gpt-neo-125m  EleutherAI-gpt-neo-125m    t5-base    xsum   \n",
       "3   EleutherAI-gpt-neo-125m          bert-base-cased    t5-base    xsum   \n",
       "5   EleutherAI-gpt-neo-125m              gpt2-medium    t5-base    xsum   \n",
       "7   EleutherAI-gpt-neo-125m                     gpt2    t5-base    xsum   \n",
       "9   EleutherAI-gpt-neo-125m             roberta-base    t5-base    xsum   \n",
       "21                     gpt2  EleutherAI-gpt-neo-125m    t5-base    xsum   \n",
       "23                     gpt2          bert-base-cased    t5-base    xsum   \n",
       "25                     gpt2              gpt2-medium    t5-base    xsum   \n",
       "27                     gpt2                     gpt2    t5-base    xsum   \n",
       "29                     gpt2             roberta-base    t5-base    xsum   \n",
       "11              gpt2-medium  EleutherAI-gpt-neo-125m    t5-base    xsum   \n",
       "13              gpt2-medium          bert-base-cased    t5-base    xsum   \n",
       "15              gpt2-medium              gpt2-medium    t5-base    xsum   \n",
       "17              gpt2-medium                     gpt2    t5-base    xsum   \n",
       "19              gpt2-medium             roberta-base    t5-base    xsum   \n",
       "\n",
       "   sampling                                             d_path  \\\n",
       "0      temp  results/permute/EleutherAI-gpt-neo-125m_Eleuth...   \n",
       "2      temp  results/permute/EleutherAI-gpt-neo-125m_bert-b...   \n",
       "4      temp  results/permute/EleutherAI-gpt-neo-125m_gpt2-m...   \n",
       "6      temp  results/permute/EleutherAI-gpt-neo-125m_gpt2_t...   \n",
       "8      temp  results/permute/EleutherAI-gpt-neo-125m_robert...   \n",
       "20     temp  results/permute/gpt2_EleutherAI-gpt-neo-125m_t...   \n",
       "22     temp  results/permute/gpt2_bert-base-cased_t5-base_g...   \n",
       "24     temp  results/permute/gpt2_gpt2-medium_t5-base_germa...   \n",
       "26     temp  results/permute/gpt2_gpt2_t5-base_german_temp/...   \n",
       "28     temp  results/permute/gpt2_roberta-base_t5-base_germ...   \n",
       "10     temp  results/permute/gpt2-medium_EleutherAI-gpt-neo...   \n",
       "12     temp  results/permute/gpt2-medium_bert-base-cased_t5...   \n",
       "14     temp  results/permute/gpt2-medium_gpt2-medium_t5-bas...   \n",
       "16     temp  results/permute/gpt2-medium_gpt2_t5-base_germa...   \n",
       "18     temp  results/permute/gpt2-medium_roberta-base_t5-ba...   \n",
       "1      temp  results/permute/EleutherAI-gpt-neo-125m_Eleuth...   \n",
       "3      temp  results/permute/EleutherAI-gpt-neo-125m_bert-b...   \n",
       "5      temp  results/permute/EleutherAI-gpt-neo-125m_gpt2-m...   \n",
       "7      temp  results/permute/EleutherAI-gpt-neo-125m_gpt2_t...   \n",
       "9      temp  results/permute/EleutherAI-gpt-neo-125m_robert...   \n",
       "21     temp  results/permute/gpt2_EleutherAI-gpt-neo-125m_t...   \n",
       "23     temp  results/permute/gpt2_bert-base-cased_t5-base_x...   \n",
       "25     temp  results/permute/gpt2_gpt2-medium_t5-base_xsum_...   \n",
       "27     temp  results/permute/gpt2_gpt2_t5-base_xsum_temp/20...   \n",
       "29     temp  results/permute/gpt2_roberta-base_t5-base_xsum...   \n",
       "11     temp  results/permute/gpt2-medium_EleutherAI-gpt-neo...   \n",
       "13     temp  results/permute/gpt2-medium_bert-base-cased_t5...   \n",
       "15     temp  results/permute/gpt2-medium_gpt2-medium_t5-bas...   \n",
       "17     temp  results/permute/gpt2-medium_gpt2_t5-base_xsum_...   \n",
       "19     temp  results/permute/gpt2-medium_roberta-base_t5-ba...   \n",
       "\n",
       "                                               z_path  \n",
       "0   results/permute/EleutherAI-gpt-neo-125m_Eleuth...  \n",
       "2   results/permute/EleutherAI-gpt-neo-125m_bert-b...  \n",
       "4   results/permute/EleutherAI-gpt-neo-125m_gpt2-m...  \n",
       "6   results/permute/EleutherAI-gpt-neo-125m_gpt2_t...  \n",
       "8   results/permute/EleutherAI-gpt-neo-125m_robert...  \n",
       "20  results/permute/gpt2_EleutherAI-gpt-neo-125m_t...  \n",
       "22  results/permute/gpt2_bert-base-cased_t5-base_g...  \n",
       "24  results/permute/gpt2_gpt2-medium_t5-base_germa...  \n",
       "26  results/permute/gpt2_gpt2_t5-base_german_temp/...  \n",
       "28  results/permute/gpt2_roberta-base_t5-base_germ...  \n",
       "10  results/permute/gpt2-medium_EleutherAI-gpt-neo...  \n",
       "12  results/permute/gpt2-medium_bert-base-cased_t5...  \n",
       "14  results/permute/gpt2-medium_gpt2-medium_t5-bas...  \n",
       "16  results/permute/gpt2-medium_gpt2_t5-base_germa...  \n",
       "18  results/permute/gpt2-medium_roberta-base_t5-ba...  \n",
       "1   results/permute/EleutherAI-gpt-neo-125m_Eleuth...  \n",
       "3   results/permute/EleutherAI-gpt-neo-125m_bert-b...  \n",
       "5   results/permute/EleutherAI-gpt-neo-125m_gpt2-m...  \n",
       "7   results/permute/EleutherAI-gpt-neo-125m_gpt2_t...  \n",
       "9   results/permute/EleutherAI-gpt-neo-125m_robert...  \n",
       "21  results/permute/gpt2_EleutherAI-gpt-neo-125m_t...  \n",
       "23  results/permute/gpt2_bert-base-cased_t5-base_x...  \n",
       "25  results/permute/gpt2_gpt2-medium_t5-base_xsum_...  \n",
       "27  results/permute/gpt2_gpt2_t5-base_xsum_temp/20...  \n",
       "29  results/permute/gpt2_roberta-base_t5-base_xsum...  \n",
       "11  results/permute/gpt2-medium_EleutherAI-gpt-neo...  \n",
       "13  results/permute/gpt2-medium_bert-base-cased_t5...  \n",
       "15  results/permute/gpt2-medium_gpt2-medium_t5-bas...  \n",
       "17  results/permute/gpt2-medium_gpt2_t5-base_xsum_...  \n",
       "19  results/permute/gpt2-medium_roberta-base_t5-ba...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(config_dicts).sort_values([\"dataset\", \"base_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "481baa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame(config_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b507cae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models = sorted(set(config_df[\"base_model\"].values))\n",
    "datasets = sorted(set(config_df[\"dataset\"].values))\n",
    "drop_scoring_base_bools = [False, True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84ca6cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_configs = list(dict(zip((\"base_model\", \"drop_scoring_base\", \"dataset\"), p)) for p in itertools.product(base_models, drop_scoring_base_bools, datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19d34f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step(df_train, df_test):\n",
    "    def cond_mean(scores, thresholds):\n",
    "        i = 0\n",
    "        while i < len(thresholds) and scores[i] < thresholds[i]:\n",
    "            i+=1\n",
    "        return np.mean(scores[:(i+1)])\n",
    "    \n",
    "    df_test[\"ms\"] = 0\n",
    "    auc_scores = []\n",
    "    for z in np.arange(0, 3, 0.1):\n",
    "        thresholds = [np.mean(df_train.loc[df_train['y'] == 1, model]) - z*np.std(df_train.loc[df_train['y'] == 1, model]) for model in df_train.columns.values[:-2]]\n",
    "        for i in range(df_train.shape[0]):\n",
    "            df_train.loc[i, \"ms\"] = cond_mean(df_train.iloc[i, :df_train.shape[1]-2].to_list(), thresholds)\n",
    "        auc_scores.append(roc_auc_score(df_train[\"y\"], df_train[\"ms\"]))\n",
    "    \n",
    "    z_star = 0.1*np.argmax(auc_scores)\n",
    "    thresholds = [np.mean(df_train.loc[df_train['y'] == 1, model]) - z_star*np.std(df_train.loc[df_train['y'] == 1, model]) for model in df_train.columns.values[:-2]]\n",
    "    for i in range(df_test.shape[0]):\n",
    "        df_test.loc[i, \"ms\"] = cond_mean(df_test.iloc[i, :df_test.shape[1]-2].to_list(), thresholds)\n",
    "    return df_test[\"ms\"]\n",
    "\n",
    "def get_aucs(**kwargs):\n",
    "    df = utils.get_pred_df(**kwargs)\n",
    "    \n",
    "    y = df[\"y\"]\n",
    "    X = df.drop(\"y\", axis=1).values\n",
    "\n",
    "    auc_dict = {}\n",
    "    best_params = {}\n",
    "    \n",
    "    for model in df.columns.values[:-1]:\n",
    "        auc_dict[model] = roc_auc_score(y, df.loc[:, model])\n",
    "\n",
    "    auc_dict[\"max\"] = roc_auc_score(y, X.max(axis=1))\n",
    "    auc_dict[\"mean\"] =  roc_auc_score(y, X.mean(axis=1))\n",
    "    auc_dict[\"median\"] = roc_auc_score(y, np.median(X, axis=1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    print(\"Training Logistic Regression\")\n",
    "    model_lr = LogisticRegression()\n",
    "    param_grid_lr = {\n",
    "        'C': [100, 10, 1, 0.1, 0.01],\n",
    "        'penalty': ['none', 'l2']\n",
    "    }\n",
    "    gs_lr = GridSearchCV(estimator=model_lr, param_grid=param_grid_lr, cv=5)\n",
    "    gs_lr.fit(X_train, y_train)\n",
    "    auc_dict[\"lr\"] = roc_auc_score(y_test, gs_lr.best_estimator_.predict_proba(X_test)[:, 1])\n",
    "    print(kwargs, gs_lr.best_estimator_.coef_)\n",
    "    \n",
    "    print(\"Training Random Forest\")\n",
    "    model_rf = RandomForestClassifier()\n",
    "    param_grid_rf = {\n",
    "        'bootstrap': [True, False],\n",
    "        'max_depth': [10, 20, 30],\n",
    "        'min_samples_split': [4, 6, 8],\n",
    "        'n_estimators': [100, 300, 500, 1000]\n",
    "    }\n",
    "    gs_rf = GridSearchCV(estimator=model_rf, param_grid=param_grid_rf, cv=3)\n",
    "    gs_rf.fit(X_train, y_train)\n",
    "    auc_dict[\"rf\"] = roc_auc_score(y_test, gs_rf.best_estimator_.predict_proba(X_test)[:, 1])\n",
    "    best_params[\"rf\"] = gs_rf.best_params_\n",
    "    \n",
    "    print(\"Training Gaussian Naive Bayes\")\n",
    "    model_nb = GaussianNB()\n",
    "    param_grid_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "    gs_nb = GridSearchCV(estimator=model_nb, param_grid = param_grid_nb, cv=3)\n",
    "    gs_nb.fit(X_train, y_train)\n",
    "    auc_dict[\"nb\"] = roc_auc_score(y_test, gs_nb.best_estimator_.predict_proba(X_test)[:, 1])\n",
    "    best_params[\"nb\"] = gs_nb.best_params_\n",
    "    \n",
    "    print(\"Training Support Vector Machine\")\n",
    "    model_sv = svm.SVC(probability=True)\n",
    "    param_grid_sv = {'C': [0.1, 1, 10, 100, 1000], \n",
    "        'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "    gs_sv = GridSearchCV(estimator=model_sv, param_grid=param_grid_sv, cv=3)\n",
    "    gs_sv.fit(X_train, y_train)\n",
    "    auc_dict[\"sv\"] = roc_auc_score(y_test, gs_sv.best_estimator_.predict_proba(X_test)[:, 1])\n",
    "    best_params[\"nb\"] = gs_sv.best_params_\n",
    "    \n",
    "    print(\"Training Multi-step\")\n",
    "    model_list = [\"gpt2-medium\", \"EleutherAI-gpt-neo-125m\", \"roberta-base\", \"gpt2\", \"bert-base-cased\", \"y\"] #355, 125, 125, 124, 110\n",
    "    df_train = pd.concat([pd.DataFrame(X_train, columns=df.columns.values[:-1]), pd.DataFrame(np.array(y_train), columns=[\"y\"])], axis=1)\n",
    "    df_test = pd.concat([pd.DataFrame(X_test, columns=df.columns.values[:-1]), pd.DataFrame(np.array(y_test), columns=[\"y\"])], axis=1)\n",
    "    df_train = df_train[[model for model in model_list if model in df_train.columns.values]]\n",
    "    df_test = df_test[[model for model in model_list if model in df_train.columns.values]]\n",
    "    auc_dict[\"ms\"] = roc_auc_score(y_test, multi_step(df_train, df_test))\n",
    "    \n",
    "    return auc_dict, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6132b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression\n",
      "{'base_model': 'EleutherAI-gpt-neo-125m', 'drop_scoring_base': False, 'dataset': 'german'} [[ 6.68863842 -0.3663044  -5.98632602  6.56389637  2.2765553 ]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'EleutherAI-gpt-neo-125m', 'drop_scoring_base': False, 'dataset': 'xsum'} [[ 40.73669723  -6.29479348 -25.67268641  -6.01410881  10.24906843]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'EleutherAI-gpt-neo-125m', 'drop_scoring_base': True, 'dataset': 'german'} [[-0.35443463 -1.7137634   5.74343978  2.01387073]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'EleutherAI-gpt-neo-125m', 'drop_scoring_base': True, 'dataset': 'xsum'} [[-0.41043512 -8.62998649  8.86258156  3.23757127]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2', 'drop_scoring_base': False, 'dataset': 'german'} [[-109.53276584  -24.48208153 -165.30197315  364.03479844   21.03121918]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2', 'drop_scoring_base': False, 'dataset': 'xsum'} [[  2.67303193  -0.88476028 -10.71580395  13.89560161   1.95293086]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2', 'drop_scoring_base': True, 'dataset': 'german'} [[-4.16164338 -0.80004317  6.21426194  1.86669993]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2', 'drop_scoring_base': True, 'dataset': 'xsum'} [[ 5.30624799  0.22443078 -1.96194219  2.20482211]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2-medium', 'drop_scoring_base': False, 'dataset': 'german'} [[-2.49907282 -0.32509808  3.34748712  1.92147095  1.7947806 ]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2-medium', 'drop_scoring_base': False, 'dataset': 'xsum'} [[ 2.91816233 -0.11548961  4.52266358 -0.12324566  3.85214286]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2-medium', 'drop_scoring_base': True, 'dataset': 'german'} [[-2.21941462 -0.15809703  4.97726363  1.45837369]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n",
      "Training Logistic Regression\n",
      "{'base_model': 'gpt2-medium', 'drop_scoring_base': True, 'dataset': 'xsum'} [[2.47510565 0.48148358 3.99018977 3.17934917]]\n",
      "Training Random Forest\n",
      "Training Gaussian Naive Bayes\n",
      "Training Support Vector Machine\n",
      "Training Multi-step\n"
     ]
    }
   ],
   "source": [
    "auc_results = [[c, get_aucs(**c)] for c in ensemble_configs]\n",
    "best_params = [[r[0], r[1][1]] for r in auc_results]\n",
    "df_ensemble_results_nested = pd.DataFrame([{**(r[0]), \"aucs\":r[1][0]} for r in auc_results])\n",
    "##df_ensemble_results_nested = pd.DataFrame([{**c, \"aucs\":get_aucs(**c)} for c in ensemble_configs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be36459e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_results = df_ensemble_results_nested.join(df_ensemble_results_nested[\"aucs\"].apply(pd.Series)).drop(\"aucs\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aed9bba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'base_model': 'EleutherAI-gpt-neo-125m',\n",
       "   'drop_scoring_base': False,\n",
       "   'dataset': 'german'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 8,\n",
       "    'n_estimators': 100},\n",
       "   'nb': {'C': 1, 'gamma': 1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'EleutherAI-gpt-neo-125m',\n",
       "   'drop_scoring_base': False,\n",
       "   'dataset': 'xsum'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 300},\n",
       "   'nb': {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'EleutherAI-gpt-neo-125m',\n",
       "   'drop_scoring_base': True,\n",
       "   'dataset': 'german'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 6,\n",
       "    'n_estimators': 100},\n",
       "   'nb': {'C': 1, 'gamma': 1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'EleutherAI-gpt-neo-125m',\n",
       "   'drop_scoring_base': True,\n",
       "   'dataset': 'xsum'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 500},\n",
       "   'nb': {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2', 'drop_scoring_base': False, 'dataset': 'german'},\n",
       "  {'rf': {'bootstrap': False,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 300},\n",
       "   'nb': {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2', 'drop_scoring_base': False, 'dataset': 'xsum'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 100},\n",
       "   'nb': {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2', 'drop_scoring_base': True, 'dataset': 'german'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 8,\n",
       "    'n_estimators': 500},\n",
       "   'nb': {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2', 'drop_scoring_base': True, 'dataset': 'xsum'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 300},\n",
       "   'nb': {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2-medium',\n",
       "   'drop_scoring_base': False,\n",
       "   'dataset': 'german'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 10,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 100},\n",
       "   'nb': {'C': 1, 'gamma': 1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2-medium', 'drop_scoring_base': False, 'dataset': 'xsum'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 30,\n",
       "    'min_samples_split': 6,\n",
       "    'n_estimators': 500},\n",
       "   'nb': {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2-medium',\n",
       "   'drop_scoring_base': True,\n",
       "   'dataset': 'german'},\n",
       "  {'rf': {'bootstrap': True,\n",
       "    'max_depth': 30,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 300},\n",
       "   'nb': {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}}],\n",
       " [{'base_model': 'gpt2-medium', 'drop_scoring_base': True, 'dataset': 'xsum'},\n",
       "  {'rf': {'bootstrap': False,\n",
       "    'max_depth': 20,\n",
       "    'min_samples_split': 4,\n",
       "    'n_estimators': 100},\n",
       "   'nb': {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}}]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea512607",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_model</th>\n",
       "      <th>scoring_model</th>\n",
       "      <th>dataset</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>german</td>\n",
       "      <td>0.953675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.998200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>german</td>\n",
       "      <td>0.369700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.628175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>german</td>\n",
       "      <td>0.823425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.696050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>german</td>\n",
       "      <td>0.775925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.247875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>german</td>\n",
       "      <td>0.465750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.840350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>german</td>\n",
       "      <td>0.281400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.932550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>german</td>\n",
       "      <td>0.274925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.563750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>german</td>\n",
       "      <td>0.988675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.978875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>german</td>\n",
       "      <td>0.836850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.536425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>german</td>\n",
       "      <td>0.558500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.757200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>german</td>\n",
       "      <td>0.305825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.899875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>german</td>\n",
       "      <td>0.283900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>bert-base-cased</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.553750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>german</td>\n",
       "      <td>0.966300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.901775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>german</td>\n",
       "      <td>0.979325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.925200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>german</td>\n",
       "      <td>0.594575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>roberta-base</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.648475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base_model            scoring_model dataset       auc\n",
       "0   EleutherAI-gpt-neo-125m  EleutherAI-gpt-neo-125m  german  0.953675\n",
       "1   EleutherAI-gpt-neo-125m  EleutherAI-gpt-neo-125m    xsum  0.998200\n",
       "2   EleutherAI-gpt-neo-125m          bert-base-cased  german  0.369700\n",
       "3   EleutherAI-gpt-neo-125m          bert-base-cased    xsum  0.628175\n",
       "6   EleutherAI-gpt-neo-125m                     gpt2  german  0.823425\n",
       "7   EleutherAI-gpt-neo-125m                     gpt2    xsum  0.696050\n",
       "4   EleutherAI-gpt-neo-125m              gpt2-medium  german  0.775925\n",
       "5   EleutherAI-gpt-neo-125m              gpt2-medium    xsum  0.247875\n",
       "8   EleutherAI-gpt-neo-125m             roberta-base  german  0.465750\n",
       "9   EleutherAI-gpt-neo-125m             roberta-base    xsum  0.840350\n",
       "20                     gpt2  EleutherAI-gpt-neo-125m  german  0.281400\n",
       "21                     gpt2  EleutherAI-gpt-neo-125m    xsum  0.932550\n",
       "22                     gpt2          bert-base-cased  german  0.274925\n",
       "23                     gpt2          bert-base-cased    xsum  0.563750\n",
       "26                     gpt2                     gpt2  german  0.988675\n",
       "27                     gpt2                     gpt2    xsum  0.978875\n",
       "24                     gpt2              gpt2-medium  german  0.836850\n",
       "25                     gpt2              gpt2-medium    xsum  0.536425\n",
       "28                     gpt2             roberta-base  german  0.558500\n",
       "29                     gpt2             roberta-base    xsum  0.757200\n",
       "10              gpt2-medium  EleutherAI-gpt-neo-125m  german  0.305825\n",
       "11              gpt2-medium  EleutherAI-gpt-neo-125m    xsum  0.899875\n",
       "12              gpt2-medium          bert-base-cased  german  0.283900\n",
       "13              gpt2-medium          bert-base-cased    xsum  0.553750\n",
       "16              gpt2-medium                     gpt2  german  0.966300\n",
       "17              gpt2-medium                     gpt2    xsum  0.901775\n",
       "14              gpt2-medium              gpt2-medium  german  0.979325\n",
       "15              gpt2-medium              gpt2-medium    xsum  0.925200\n",
       "18              gpt2-medium             roberta-base  german  0.594575\n",
       "19              gpt2-medium             roberta-base    xsum  0.648475"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_auc_single().sort_values([\"base_model\", \"scoring_model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd6588e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EleutherAI-gpt-neo-125m  bert-base-cased  gpt2-medium      gpt2  \\\n",
      "0                 0.953675         0.369700     0.775925  0.823425   \n",
      "1                 0.998200         0.628175     0.247875  0.696050   \n",
      "4                 0.281400         0.274925     0.836850  0.988675   \n",
      "5                 0.932550         0.563750     0.536425  0.978875   \n",
      "8                 0.305825         0.283900     0.979325  0.966300   \n",
      "9                 0.899875         0.553750     0.925200  0.901775   \n",
      "\n",
      "   roberta-base  \n",
      "0      0.465750  \n",
      "1      0.840350  \n",
      "4      0.558500  \n",
      "5      0.757200  \n",
      "8      0.594575  \n",
      "9      0.648475  \n",
      "EleutherAI-gpt-neo-125m    0.728588\n",
      "bert-base-cased            0.445700\n",
      "gpt2-medium                0.716933\n",
      "gpt2                       0.892517\n",
      "roberta-base               0.644142\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table_3 = df_ensemble_results[df_ensemble_results['drop_scoring_base']==False].iloc[:, 3:8]\n",
    "table_3_avg = np.mean(df_ensemble_results[df_ensemble_results['drop_scoring_base']==False].iloc[:, 3:8], axis=0)\n",
    "print(table_3)\n",
    "print(table_3_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b87b2c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2     0.608700\n",
      "3     0.603113\n",
      "6     0.487919\n",
      "7     0.697481\n",
      "10    0.537650\n",
      "11    0.750969\n",
      "dtype: float64\n",
      "0.6143052083333335\n",
      "         max      mean    median\n",
      "2   0.633600  0.730225  0.765425\n",
      "3   0.318825  0.721425  0.739750\n",
      "6   0.545200  0.434125  0.452700\n",
      "7   0.557825  0.884550  0.910900\n",
      "10  0.776175  0.683425  0.637700\n",
      "11  0.899350  0.932275  0.878725\n",
      "max       0.621829\n",
      "mean      0.731004\n",
      "median    0.730867\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "table_4_baseline = np.mean(df_ensemble_results[df_ensemble_results['drop_scoring_base']==True].iloc[:, 3:8], axis=1)\n",
    "table_4_baseline_avg = np.mean(table_4_baseline)\n",
    "print(table_4_baseline)\n",
    "print(table_4_baseline_avg)\n",
    "table_4_sum_stats = df_ensemble_results[df_ensemble_results['drop_scoring_base']==True].iloc[:, 8:11]\n",
    "print(table_4_sum_stats)\n",
    "print(np.mean(table_4_sum_stats, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e3c88ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 base_model  drop_scoring_base dataset  \\\n",
      "0   EleutherAI-gpt-neo-125m              False  german   \n",
      "1   EleutherAI-gpt-neo-125m              False    xsum   \n",
      "2   EleutherAI-gpt-neo-125m               True  german   \n",
      "3   EleutherAI-gpt-neo-125m               True    xsum   \n",
      "4                      gpt2              False  german   \n",
      "5                      gpt2              False    xsum   \n",
      "6                      gpt2               True  german   \n",
      "7                      gpt2               True    xsum   \n",
      "8               gpt2-medium              False  german   \n",
      "9               gpt2-medium              False    xsum   \n",
      "10              gpt2-medium               True  german   \n",
      "11              gpt2-medium               True    xsum   \n",
      "\n",
      "    EleutherAI-gpt-neo-125m  bert-base-cased  gpt2-medium      gpt2  \\\n",
      "0                  0.953675         0.369700     0.775925  0.823425   \n",
      "1                  0.998200         0.628175     0.247875  0.696050   \n",
      "2                       NaN         0.369700     0.775925  0.823425   \n",
      "3                       NaN         0.628175     0.247875  0.696050   \n",
      "4                  0.281400         0.274925     0.836850  0.988675   \n",
      "5                  0.932550         0.563750     0.536425  0.978875   \n",
      "6                  0.281400         0.274925     0.836850       NaN   \n",
      "7                  0.932550         0.563750     0.536425       NaN   \n",
      "8                  0.305825         0.283900     0.979325  0.966300   \n",
      "9                  0.899875         0.553750     0.925200  0.901775   \n",
      "10                 0.305825         0.283900          NaN  0.966300   \n",
      "11                 0.899875         0.553750          NaN  0.901775   \n",
      "\n",
      "    roberta-base       max      mean    median        lr        rf        nb  \\\n",
      "0       0.465750  0.948550  0.891050  0.780375  0.951149  0.971264  0.914204   \n",
      "1       0.840350  0.783300  0.922950  0.846525  1.000000  1.000000  1.000000   \n",
      "2       0.465750  0.633600  0.730225  0.765425  0.779557  0.797209  0.765189   \n",
      "3       0.840350  0.318825  0.721425  0.739750  0.975369  0.972496  0.947044   \n",
      "4       0.558500  0.911950  0.825625  0.719425  0.987890  0.997947  0.996305   \n",
      "5       0.757200  0.817600  0.946425  0.933750  1.000000  1.000000  0.996716   \n",
      "6       0.558500  0.545200  0.434125  0.452700  0.933908  0.926519  0.902299   \n",
      "7       0.757200  0.557825  0.884550  0.910900  0.996305  0.991379  0.984811   \n",
      "8       0.594575  0.930225  0.912325  0.811975  0.991790  0.987685  0.986043   \n",
      "9       0.648475  0.925200  0.956850  0.906950  0.971264  0.958539  0.934319   \n",
      "10      0.594575  0.776175  0.683425  0.637700  0.987274  0.978243  0.978243   \n",
      "11      0.648475  0.899350  0.932275  0.878725  0.957307  0.948276  0.933908   \n",
      "\n",
      "          sv        ms  \n",
      "0   0.969212  0.818555  \n",
      "1   1.000000  0.425287  \n",
      "2   0.818144  0.741379  \n",
      "3   0.980296  0.360427  \n",
      "4   0.998768  0.827997  \n",
      "5   1.000000  0.676108  \n",
      "6   0.932677  0.827997  \n",
      "7   0.996305  0.671593  \n",
      "8   0.977833  0.974138  \n",
      "9   0.954023  0.947455  \n",
      "10  0.983580  0.384647  \n",
      "11  0.956486  0.933908  \n",
      "          lr        rf        nb        sv        ms\n",
      "2   0.779557  0.797209  0.765189  0.818144  0.741379\n",
      "3   0.975369  0.972496  0.947044  0.980296  0.360427\n",
      "6   0.933908  0.926519  0.902299  0.932677  0.827997\n",
      "7   0.996305  0.991379  0.984811  0.996305  0.671593\n",
      "10  0.987274  0.978243  0.978243  0.983580  0.384647\n",
      "11  0.957307  0.948276  0.933908  0.956486  0.933908\n",
      "lr    0.938287\n",
      "rf    0.935687\n",
      "nb    0.918582\n",
      "sv    0.944581\n",
      "ms    0.653325\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_ensemble_results)\n",
    "table_5_supervised = df_ensemble_results[df_ensemble_results['drop_scoring_base']==True].iloc[:, 11:16]\n",
    "print(table_5_supervised)\n",
    "print(np.mean(table_5_supervised, axis=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
