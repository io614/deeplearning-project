{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b75ca790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc375d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_df = pd.DataFrame(utils.get_config_dicts())\n",
    "base_models = sorted(set(config_df[\"base_model\"].values))\n",
    "datasets = sorted(set(config_df[\"dataset\"].values))\n",
    "drop_scoring_base_bools = [False, True]\n",
    "ensemble_configs = list(dict(zip((\"base_model\", \"drop_scoring_base\", \"dataset\"), p)) for p in itertools.product(base_models, drop_scoring_base_bools, datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "83c09865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step(df_train, df_test):\n",
    "    def cond_mean(scores, thresholds):\n",
    "        i = 0\n",
    "        while i < len(thresholds) and scores[i] < thresholds[i]:\n",
    "            i+=1\n",
    "        return np.mean(scores[:(i+1)])\n",
    "    \n",
    "    df_test[\"ms\"] = 0\n",
    "    auc_scores = []\n",
    "    for z in np.arange(0, 3, 0.1):\n",
    "        thresholds = [np.mean(df_train.loc[df_train['y'] == 1, model]) - z*np.std(df_train.loc[df_train['y'] == 1, model]) for model in df_train.columns.values[:-2]]\n",
    "        for i in range(df_train.shape[0]):\n",
    "            df_train.loc[i, \"ms\"] = cond_mean(df_train.iloc[i, :df_train.shape[1]-2].to_list(), thresholds)\n",
    "        auc_scores.append(roc_auc_score(df_train[\"y\"], df_train[\"ms\"]))\n",
    "    \n",
    "    z_star = 0.1*np.argmax(auc_scores)\n",
    "    thresholds = [np.mean(df_train.loc[df_train['y'] == 1, model]) - z_star*np.std(df_train.loc[df_train['y'] == 1, model]) for model in df_train.columns.values[:-2]]\n",
    "    for i in range(df_test.shape[0]):\n",
    "        df_test.loc[i, \"ms\"] = cond_mean(df_test.iloc[i, :df_test.shape[1]-2].to_list(), thresholds)\n",
    "    return df_test[\"ms\"]\n",
    "\n",
    "def get_aucs(**kwargs):\n",
    "    df = utils.get_pred_df(**kwargs)\n",
    "    \n",
    "    y = df[\"y\"]\n",
    "    X = df.drop(\"y\", axis=1).values\n",
    "\n",
    "    auc_dict = {}\n",
    "    \n",
    "    for model in df.columns.values[:-1]:\n",
    "        auc_dict[model] = roc_auc_score(y, df.loc[:, model])\n",
    "\n",
    "    auc_dict[\"max\"] = roc_auc_score(y, X.max(axis=1))\n",
    "    auc_dict[\"mean\"] =  roc_auc_score(y, X.mean(axis=1))\n",
    "    auc_dict[\"median\"] = roc_auc_score(y, np.median(X, axis=1))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    model_lr = LogisticRegression()\n",
    "    model_lr.fit(X_train, y_train)\n",
    "    auc_dict[\"lr\"] = roc_auc_score(y_test, model_lr.predict_proba(X_test)[:, 1])\n",
    "\n",
    "    model_rf = RandomForestClassifier()\n",
    "    model_rf.fit(X_train, y_train)\n",
    "    auc_dict[\"rf\"] = roc_auc_score(y_test, model_rf.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    model_nb = GaussianNB()\n",
    "    model_nb.fit(X_train, y_train)\n",
    "    auc_dict[\"nb\"] = roc_auc_score(y_test, model_nb.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    model_sv = svm.SVC(probability=True)\n",
    "    model_sv.fit(X_train, y_train)\n",
    "    auc_dict[\"sv\"] = roc_auc_score(y_test, model_sv.predict_proba(X_test)[:, 1])\n",
    "    \n",
    "    model_list = [\"gpt2-medium\", \"EleutherAI-gpt-neo-125m\", \"roberta-base\", \"gpt2\", \"bert-base-cased\", \"y\"] #355, 125, 125, 124, 110\n",
    "    df_train = pd.concat([pd.DataFrame(X_train, columns=df.columns.values[:-1]), pd.DataFrame(np.array(y_train), columns=[\"y\"])], axis=1)\n",
    "    df_test = pd.concat([pd.DataFrame(X_test, columns=df.columns.values[:-1]), pd.DataFrame(np.array(y_test), columns=[\"y\"])], axis=1)\n",
    "    df_train = df_train[[model for model in model_list if model in df_train.columns.values]]\n",
    "    df_test = df_test[[model for model in model_list if model in df_train.columns.values]]\n",
    "    auc_dict[\"ms\"] = roc_auc_score(y_test, multi_step(df_train, df_test))\n",
    "    \n",
    "    return auc_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "15ca6130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 base_model  drop_scoring_base dataset  \\\n",
      "0   EleutherAI-gpt-neo-125m              False  german   \n",
      "1   EleutherAI-gpt-neo-125m              False    xsum   \n",
      "2   EleutherAI-gpt-neo-125m               True  german   \n",
      "3   EleutherAI-gpt-neo-125m               True    xsum   \n",
      "4                      gpt2              False  german   \n",
      "5                      gpt2              False    xsum   \n",
      "6                      gpt2               True  german   \n",
      "7                      gpt2               True    xsum   \n",
      "8               gpt2-medium              False  german   \n",
      "9               gpt2-medium              False    xsum   \n",
      "10              gpt2-medium               True  german   \n",
      "11              gpt2-medium               True    xsum   \n",
      "\n",
      "    EleutherAI-gpt-neo-125m  bert-base-cased  gpt2-medium      gpt2  \\\n",
      "0                  0.953675         0.369700     0.775925  0.823425   \n",
      "1                  0.998200         0.628175     0.247875  0.696050   \n",
      "2                       NaN         0.369700     0.775925  0.823425   \n",
      "3                       NaN         0.628175     0.247875  0.696050   \n",
      "4                  0.281400         0.274925     0.836850  0.988675   \n",
      "5                  0.932550         0.563750     0.536425  0.978875   \n",
      "6                  0.281400         0.274925     0.836850       NaN   \n",
      "7                  0.932550         0.563750     0.536425       NaN   \n",
      "8                  0.305825         0.283900     0.979325  0.966300   \n",
      "9                  0.899875         0.553750     0.925200  0.901775   \n",
      "10                 0.305825         0.283900          NaN  0.966300   \n",
      "11                 0.899875         0.553750          NaN  0.901775   \n",
      "\n",
      "    roberta-base       max      mean    median        lr        rf        nb  \\\n",
      "0       0.465750  0.948550  0.891050  0.780375  0.951970  0.975164  0.923645   \n",
      "1       0.840350  0.783300  0.922950  0.846525  1.000000  1.000000  1.000000   \n",
      "2       0.465750  0.633600  0.730225  0.765425  0.780378  0.801314  0.773399   \n",
      "3       0.840350  0.318825  0.721425  0.739750  0.981117  0.974343  0.945402   \n",
      "4       0.558500  0.911950  0.825625  0.719425  0.999589  0.999179  0.995895   \n",
      "5       0.757200  0.817600  0.946425  0.933750  1.000000  1.000000  0.997126   \n",
      "6       0.558500  0.545200  0.434125  0.452700  0.934319  0.921182  0.899015   \n",
      "7       0.757200  0.557825  0.884550  0.910900  0.996305  0.987890  0.982759   \n",
      "8       0.594575  0.930225  0.912325  0.811975  0.991790  0.989122  0.980706   \n",
      "9       0.648475  0.925200  0.956850  0.906950  0.969622  0.954228  0.935550   \n",
      "10      0.594575  0.776175  0.683425  0.637700  0.987274  0.979885  0.974138   \n",
      "11      0.648475  0.899350  0.932275  0.878725  0.957307  0.952997  0.934319   \n",
      "\n",
      "          sv        ms  \n",
      "0   0.967570  0.818555  \n",
      "1   1.000000  0.425287  \n",
      "2   0.816913  0.741379  \n",
      "3   0.981527  0.360427  \n",
      "4   1.000000  0.827997  \n",
      "5   1.000000  0.676108  \n",
      "6   0.921182  0.827997  \n",
      "7   0.995074  0.671593  \n",
      "8   0.983580  0.974138  \n",
      "9   0.970854  0.947455  \n",
      "10  0.974959  0.384647  \n",
      "11  0.954433  0.933908  \n",
      "drop_scoring_base          1.000000\n",
      "EleutherAI-gpt-neo-125m    0.604912\n",
      "bert-base-cased            0.445700\n",
      "gpt2-medium                0.599269\n",
      "gpt2                       0.846888\n",
      "roberta-base               0.644142\n",
      "max                        0.621829\n",
      "mean                       0.731004\n",
      "median                     0.730867\n",
      "lr                         0.939450\n",
      "rf                         0.936268\n",
      "nb                         0.918172\n",
      "sv                         0.940681\n",
      "ms                         0.653325\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jcyskr/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3438: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "df_ensemble_results_nested = pd.DataFrame([{**c, \"aucs\":get_aucs(**c)} for c in ensemble_configs])\n",
    "df_ensemble_results = df_ensemble_results_nested.join(df_ensemble_results_nested[\"aucs\"].apply(pd.Series)).drop(\"aucs\", axis=1)\n",
    "print(df_ensemble_results)\n",
    "print(np.mean(df_ensemble_results[df_ensemble_results[\"drop_scoring_base\"]==True], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "95e43c83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_model</th>\n",
       "      <th>drop_scoring_base</th>\n",
       "      <th>dataset</th>\n",
       "      <th>EleutherAI-gpt-neo-125m</th>\n",
       "      <th>bert-base-cased</th>\n",
       "      <th>gpt2-medium</th>\n",
       "      <th>gpt2</th>\n",
       "      <th>roberta-base</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>lr</th>\n",
       "      <th>rf</th>\n",
       "      <th>nb</th>\n",
       "      <th>sv</th>\n",
       "      <th>ms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>False</td>\n",
       "      <td>german</td>\n",
       "      <td>0.953675</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>0.823425</td>\n",
       "      <td>0.465750</td>\n",
       "      <td>0.948550</td>\n",
       "      <td>0.891050</td>\n",
       "      <td>0.780375</td>\n",
       "      <td>0.951970</td>\n",
       "      <td>0.975164</td>\n",
       "      <td>0.923645</td>\n",
       "      <td>0.967570</td>\n",
       "      <td>0.818555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>False</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.998200</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.247875</td>\n",
       "      <td>0.696050</td>\n",
       "      <td>0.840350</td>\n",
       "      <td>0.783300</td>\n",
       "      <td>0.922950</td>\n",
       "      <td>0.846525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.425287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>True</td>\n",
       "      <td>german</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.369700</td>\n",
       "      <td>0.775925</td>\n",
       "      <td>0.823425</td>\n",
       "      <td>0.465750</td>\n",
       "      <td>0.633600</td>\n",
       "      <td>0.730225</td>\n",
       "      <td>0.765425</td>\n",
       "      <td>0.780378</td>\n",
       "      <td>0.801314</td>\n",
       "      <td>0.773399</td>\n",
       "      <td>0.816913</td>\n",
       "      <td>0.741379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EleutherAI-gpt-neo-125m</td>\n",
       "      <td>True</td>\n",
       "      <td>xsum</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.628175</td>\n",
       "      <td>0.247875</td>\n",
       "      <td>0.696050</td>\n",
       "      <td>0.840350</td>\n",
       "      <td>0.318825</td>\n",
       "      <td>0.721425</td>\n",
       "      <td>0.739750</td>\n",
       "      <td>0.981117</td>\n",
       "      <td>0.974343</td>\n",
       "      <td>0.945402</td>\n",
       "      <td>0.981527</td>\n",
       "      <td>0.360427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>False</td>\n",
       "      <td>german</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.274925</td>\n",
       "      <td>0.836850</td>\n",
       "      <td>0.988675</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.911950</td>\n",
       "      <td>0.825625</td>\n",
       "      <td>0.719425</td>\n",
       "      <td>0.999589</td>\n",
       "      <td>0.999179</td>\n",
       "      <td>0.995895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.827997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>False</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.932550</td>\n",
       "      <td>0.563750</td>\n",
       "      <td>0.536425</td>\n",
       "      <td>0.978875</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>0.817600</td>\n",
       "      <td>0.946425</td>\n",
       "      <td>0.933750</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997126</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.676108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>True</td>\n",
       "      <td>german</td>\n",
       "      <td>0.281400</td>\n",
       "      <td>0.274925</td>\n",
       "      <td>0.836850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.558500</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.434125</td>\n",
       "      <td>0.452700</td>\n",
       "      <td>0.934319</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.899015</td>\n",
       "      <td>0.921182</td>\n",
       "      <td>0.827997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>True</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.932550</td>\n",
       "      <td>0.563750</td>\n",
       "      <td>0.536425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.757200</td>\n",
       "      <td>0.557825</td>\n",
       "      <td>0.884550</td>\n",
       "      <td>0.910900</td>\n",
       "      <td>0.996305</td>\n",
       "      <td>0.987890</td>\n",
       "      <td>0.982759</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.671593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>False</td>\n",
       "      <td>german</td>\n",
       "      <td>0.305825</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>0.979325</td>\n",
       "      <td>0.966300</td>\n",
       "      <td>0.594575</td>\n",
       "      <td>0.930225</td>\n",
       "      <td>0.912325</td>\n",
       "      <td>0.811975</td>\n",
       "      <td>0.991790</td>\n",
       "      <td>0.989122</td>\n",
       "      <td>0.980706</td>\n",
       "      <td>0.983580</td>\n",
       "      <td>0.974138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>False</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.899875</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>0.925200</td>\n",
       "      <td>0.901775</td>\n",
       "      <td>0.648475</td>\n",
       "      <td>0.925200</td>\n",
       "      <td>0.956850</td>\n",
       "      <td>0.906950</td>\n",
       "      <td>0.969622</td>\n",
       "      <td>0.954228</td>\n",
       "      <td>0.935550</td>\n",
       "      <td>0.970854</td>\n",
       "      <td>0.947455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>True</td>\n",
       "      <td>german</td>\n",
       "      <td>0.305825</td>\n",
       "      <td>0.283900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.966300</td>\n",
       "      <td>0.594575</td>\n",
       "      <td>0.776175</td>\n",
       "      <td>0.683425</td>\n",
       "      <td>0.637700</td>\n",
       "      <td>0.987274</td>\n",
       "      <td>0.979885</td>\n",
       "      <td>0.974138</td>\n",
       "      <td>0.974959</td>\n",
       "      <td>0.384647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt2-medium</td>\n",
       "      <td>True</td>\n",
       "      <td>xsum</td>\n",
       "      <td>0.899875</td>\n",
       "      <td>0.553750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.901775</td>\n",
       "      <td>0.648475</td>\n",
       "      <td>0.899350</td>\n",
       "      <td>0.932275</td>\n",
       "      <td>0.878725</td>\n",
       "      <td>0.957307</td>\n",
       "      <td>0.952997</td>\n",
       "      <td>0.934319</td>\n",
       "      <td>0.954433</td>\n",
       "      <td>0.933908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 base_model  drop_scoring_base dataset  \\\n",
       "0   EleutherAI-gpt-neo-125m              False  german   \n",
       "1   EleutherAI-gpt-neo-125m              False    xsum   \n",
       "2   EleutherAI-gpt-neo-125m               True  german   \n",
       "3   EleutherAI-gpt-neo-125m               True    xsum   \n",
       "4                      gpt2              False  german   \n",
       "5                      gpt2              False    xsum   \n",
       "6                      gpt2               True  german   \n",
       "7                      gpt2               True    xsum   \n",
       "8               gpt2-medium              False  german   \n",
       "9               gpt2-medium              False    xsum   \n",
       "10              gpt2-medium               True  german   \n",
       "11              gpt2-medium               True    xsum   \n",
       "\n",
       "    EleutherAI-gpt-neo-125m  bert-base-cased  gpt2-medium      gpt2  \\\n",
       "0                  0.953675         0.369700     0.775925  0.823425   \n",
       "1                  0.998200         0.628175     0.247875  0.696050   \n",
       "2                       NaN         0.369700     0.775925  0.823425   \n",
       "3                       NaN         0.628175     0.247875  0.696050   \n",
       "4                  0.281400         0.274925     0.836850  0.988675   \n",
       "5                  0.932550         0.563750     0.536425  0.978875   \n",
       "6                  0.281400         0.274925     0.836850       NaN   \n",
       "7                  0.932550         0.563750     0.536425       NaN   \n",
       "8                  0.305825         0.283900     0.979325  0.966300   \n",
       "9                  0.899875         0.553750     0.925200  0.901775   \n",
       "10                 0.305825         0.283900          NaN  0.966300   \n",
       "11                 0.899875         0.553750          NaN  0.901775   \n",
       "\n",
       "    roberta-base       max      mean    median        lr        rf        nb  \\\n",
       "0       0.465750  0.948550  0.891050  0.780375  0.951970  0.975164  0.923645   \n",
       "1       0.840350  0.783300  0.922950  0.846525  1.000000  1.000000  1.000000   \n",
       "2       0.465750  0.633600  0.730225  0.765425  0.780378  0.801314  0.773399   \n",
       "3       0.840350  0.318825  0.721425  0.739750  0.981117  0.974343  0.945402   \n",
       "4       0.558500  0.911950  0.825625  0.719425  0.999589  0.999179  0.995895   \n",
       "5       0.757200  0.817600  0.946425  0.933750  1.000000  1.000000  0.997126   \n",
       "6       0.558500  0.545200  0.434125  0.452700  0.934319  0.921182  0.899015   \n",
       "7       0.757200  0.557825  0.884550  0.910900  0.996305  0.987890  0.982759   \n",
       "8       0.594575  0.930225  0.912325  0.811975  0.991790  0.989122  0.980706   \n",
       "9       0.648475  0.925200  0.956850  0.906950  0.969622  0.954228  0.935550   \n",
       "10      0.594575  0.776175  0.683425  0.637700  0.987274  0.979885  0.974138   \n",
       "11      0.648475  0.899350  0.932275  0.878725  0.957307  0.952997  0.934319   \n",
       "\n",
       "          sv        ms  \n",
       "0   0.967570  0.818555  \n",
       "1   1.000000  0.425287  \n",
       "2   0.816913  0.741379  \n",
       "3   0.981527  0.360427  \n",
       "4   1.000000  0.827997  \n",
       "5   1.000000  0.676108  \n",
       "6   0.921182  0.827997  \n",
       "7   0.995074  0.671593  \n",
       "8   0.983580  0.974138  \n",
       "9   0.970854  0.947455  \n",
       "10  0.974959  0.384647  \n",
       "11  0.954433  0.933908  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ensemble_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
